{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec30f401",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'null' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      1\u001b[39m {\n\u001b[32m      2\u001b[39m  \u001b[33m\"\u001b[39m\u001b[33mcells\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m      3\u001b[39m   {\n\u001b[32m      4\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmarkdown\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m      6\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Book Recommender with Free Embeddings (Hugging Face)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mThis notebook uses Hugging Face\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms free Inference API for embeddings instead of OpenAI.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m    ]\n\u001b[32m     11\u001b[39m   },\n\u001b[32m     12\u001b[39m   {\n\u001b[32m     13\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mnull\u001b[49m,\n\u001b[32m     15\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m     16\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m     17\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     18\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Install required packages if not already installed\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     19\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# !pip install langchain-community langchain-text-splitters langchain-chroma requests python-dotenv pandas\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     20\u001b[39m    ]\n\u001b[32m     21\u001b[39m   },\n\u001b[32m     22\u001b[39m   {\n\u001b[32m     23\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     24\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m     25\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m     26\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m     27\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     28\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfrom langchain_community.document_loaders import TextLoader\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     29\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfrom langchain_text_splitters import CharacterTextSplitter\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     30\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfrom langchain_chroma import Chroma\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     31\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mimport requests\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     32\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mimport json\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     33\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mimport numpy as np\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     34\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfrom typing import List\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     35\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfrom dotenv import load_dotenv\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     36\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     37\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mload_dotenv()\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     38\u001b[39m    ]\n\u001b[32m     39\u001b[39m   },\n\u001b[32m     40\u001b[39m   {\n\u001b[32m     41\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     42\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m     43\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m     44\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m     45\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     46\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Custom Hugging Face Embeddings Class\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     47\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mclass HuggingFaceEmbeddings:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     48\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    def __init__(self, api_token=None, model_name=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33msentence-transformers/all-MiniLM-L6-v2\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     49\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        self.api_token = api_token or os.getenv(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mHUGGINGFACE_API_TOKEN\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     50\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        self.model_name = model_name\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     51\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        self.api_url = f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mhttps://api-inference.huggingface.co/pipeline/feature-extraction/\u001b[39m\u001b[38;5;132;01m{model_name}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     52\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     53\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        if not self.api_token:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     54\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m            print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mWarning: No Hugging Face API token found. Please set HUGGINGFACE_API_TOKEN in your .env file\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     55\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m            print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mYou can get a free token from: https://huggingface.co/settings/tokens\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     56\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     57\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    def embed_documents(self, texts: List[str]) -> List[List[float]]:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     58\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mEmbed a list of documents using Hugging Face API\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     59\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        if not self.api_token:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     60\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m            raise ValueError(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mHugging Face API token is required\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     61\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     62\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        headers = \u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mAuthorization\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m: f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mBearer \u001b[39m\u001b[38;5;132;01m{self.api_token}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m}\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     63\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     64\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        embeddings = []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     65\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        for text in texts:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     66\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m            try:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     67\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m                response = requests.post(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     68\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m                    self.api_url,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     69\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m                    headers=headers,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     70\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m                    json=\u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33minputs\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m: text, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33moptions\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m: \u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mwait_for_model\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m: True}}\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     71\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m                )\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     72\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m                response.raise_for_status()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     73\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m                embedding = response.json()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     74\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m                # Convert to list of floats\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     75\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m                if isinstance(embedding, list) and len(embedding) > 0:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     76\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m                    embeddings.append(embedding[0])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     77\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m                else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     78\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m                    embeddings.append(embedding)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     79\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m            except Exception as e:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     80\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m                print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mError embedding text: \u001b[39m\u001b[38;5;132;01m{e}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     81\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m                # Return zero vector as fallback\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     82\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m                embeddings.append([0.0] * 384)  # Default size for all-MiniLM-L6-v2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     83\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     84\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        return embeddings\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     85\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     86\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    def embed_query(self, text: str) -> List[float]:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     87\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mEmbed a single query text\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     88\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        return self.embed_documents([text])[0]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     89\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     90\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Alternative: Local embeddings (completely free, no API needed)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     91\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mclass LocalEmbeddings:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     92\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    def __init__(self, model_name=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     93\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        try:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     94\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m            from sentence_transformers import SentenceTransformer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     95\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m            self.model = SentenceTransformer(model_name)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     96\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m            print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mUsing local model: \u001b[39m\u001b[38;5;132;01m{model_name}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     97\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        except ImportError:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m            print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33msentence-transformers not installed. Run: pip install sentence-transformers\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     99\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m            raise\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    100\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    101\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    def embed_documents(self, texts: List[str]) -> List[List[float]]:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    102\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mEmbed documents using local model\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    103\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        return self.model.encode(texts).tolist()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    104\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    105\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    def embed_query(self, text: str) -> List[float]:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    106\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mEmbed a single query text\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    107\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        return self.model.encode([text]).tolist()[0]\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    108\u001b[39m    ]\n\u001b[32m    109\u001b[39m   },\n\u001b[32m    110\u001b[39m   {\n\u001b[32m    111\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    112\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m    113\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m    114\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m    115\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    116\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mimport pandas as pd\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    117\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mimport os\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    118\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    119\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbooks = pd.read_csv(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mbooks_cleaned.csv\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    120\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbooks.head()\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    121\u001b[39m    ]\n\u001b[32m    122\u001b[39m   },\n\u001b[32m    123\u001b[39m   {\n\u001b[32m    124\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    125\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m    126\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m    127\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m    128\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    129\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Save book descriptions to text file\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    130\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbooks[\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mtagged_description\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m].to_csv(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mtagged_descriptions.txt\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    131\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m                                     index=False,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    132\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m                                     header=False,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    133\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m                                   )\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    134\u001b[39m    ]\n\u001b[32m    135\u001b[39m   },\n\u001b[32m    136\u001b[39m   {\n\u001b[32m    137\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    138\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m    139\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m    140\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m    141\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    142\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Load and split documents\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    143\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mraw_documents = TextLoader(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mtagged_descriptions.txt\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m).load()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    144\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    145\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtext_splitter = CharacterTextSplitter(chunk_size=0, chunk_overlap=0, separator=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    146\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdocuments = text_splitter.split_documents(raw_documents)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    147\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    148\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprint(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mCreated \u001b[39m\u001b[33m{\u001b[39m\u001b[33mlen(documents)} document chunks\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    149\u001b[39m    ]\n\u001b[32m    150\u001b[39m   },\n\u001b[32m    151\u001b[39m   {\n\u001b[32m    152\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    153\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m    154\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m    155\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m    156\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    157\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Choose your embedding method:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    158\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Option 1: Hugging Face API (requires API token)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    159\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Option 2: Local embeddings (completely free, no API needed)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    160\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    161\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# For Hugging Face API (uncomment if you have API token):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    162\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# embeddings = HuggingFaceEmbeddings()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    163\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    164\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# For local embeddings (recommended for free usage):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    165\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33membeddings = LocalEmbeddings()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    166\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    167\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mEmbeddings initialized successfully!\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m    ]\n\u001b[32m    169\u001b[39m   },\n\u001b[32m    170\u001b[39m   {\n\u001b[32m    171\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    172\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m    173\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m    174\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m    175\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    176\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Create vector database\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    177\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdb_books = Chroma.from_documents(documents, embedding=embeddings)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    178\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mVector database created successfully!\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    179\u001b[39m    ]\n\u001b[32m    180\u001b[39m   },\n\u001b[32m    181\u001b[39m   {\n\u001b[32m    182\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    183\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m    184\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m    185\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m    186\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    187\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Test the search functionality\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    188\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mquery = \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33msci-fi space adventure\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    189\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mresults = db_books.similarity_search(query, k=3)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    190\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    191\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprint(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mSearch results for: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{query}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    192\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m * 50)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    193\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfor i, result in enumerate(results, 1):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    194\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mnResult \u001b[39m\u001b[38;5;132;01m{i}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    195\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    print(result.page_content[:200] + \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m...\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m if len(result.page_content) > 200 else result.page_content)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    196\u001b[39m    ]\n\u001b[32m    197\u001b[39m   },\n\u001b[32m    198\u001b[39m   {\n\u001b[32m    199\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    200\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m    201\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m    202\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m    203\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    204\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Function to get book recommendations\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    205\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdef get_book_recommendations(query, k=5):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    206\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mGet book recommendations based on a query\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    207\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    results = db_books.similarity_search(query, k=k)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    208\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    209\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    recommendations = []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    210\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    for i, result in enumerate(results, 1):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    211\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        # Extract book title from the description (assuming it\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms the first part)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    212\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        content = result.page_content\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    213\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        title = content.split(\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)[0] if \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in content else content[:50]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    214\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    215\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        recommendations.append(\u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    216\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mrank\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: i,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    217\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: title,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    218\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: content[:200] + \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m...\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m if len(content) > 200 else content\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    219\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        })\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    220\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    221\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    return recommendations\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    222\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    223\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Test with different queries\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtest_queries = [\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mmystery detective crime\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mromance love story\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mfantasy magic dragons\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    228\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mhistorical fiction war\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    229\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    230\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    231\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfor query in test_queries:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    232\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mn\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mnRecommendations for: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{query}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    233\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m * 60)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    234\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    recommendations = get_book_recommendations(query, k=3)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    235\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    236\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    for rec in recommendations:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    237\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mn\u001b[39m\u001b[38;5;132;01m{rec['rank']}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m{rec['title']}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    238\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m        print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m   \u001b[39m\u001b[38;5;132;01m{rec['description']}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    239\u001b[39m    ]\n\u001b[32m    240\u001b[39m   }\n\u001b[32m    241\u001b[39m  ],\n\u001b[32m    242\u001b[39m  \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m    243\u001b[39m   \u001b[33m\"\u001b[39m\u001b[33mkernelspec\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m    244\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mdisplay_name\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mPython 3\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    245\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mlanguage\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    246\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpython3\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    247\u001b[39m   },\n\u001b[32m    248\u001b[39m   \u001b[33m\"\u001b[39m\u001b[33mlanguage_info\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m    249\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcodemirror_mode\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m    250\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mipython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    251\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mversion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m3\u001b[39m\n\u001b[32m    252\u001b[39m    },\n\u001b[32m    253\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mfile_extension\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m.py\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    254\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmimetype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtext/x-python\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    255\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    256\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mnbconvert_exporter\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    257\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mpygments_lexer\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mipython3\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    258\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mversion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m3.8.5\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    259\u001b[39m   }\n\u001b[32m    260\u001b[39m  },\n\u001b[32m    261\u001b[39m  \u001b[33m\"\u001b[39m\u001b[33mnbformat\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m4\u001b[39m,\n\u001b[32m    262\u001b[39m  \u001b[33m\"\u001b[39m\u001b[33mnbformat_minor\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m4\u001b[39m\n\u001b[32m    263\u001b[39m }\n",
      "\u001b[31mNameError\u001b[39m: name 'null' is not defined"
     ]
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Book Recommender with Free Embeddings (Hugging Face)\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook uses Hugging Face's free Inference API for embeddings instead of OpenAI.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Install required packages if not already installed\\n\",\n",
    "    \"# !pip install langchain-community langchain-text-splitters langchain-chroma requests python-dotenv pandas\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from langchain_community.document_loaders import TextLoader\\n\",\n",
    "    \"from langchain_text_splitters import CharacterTextSplitter\\n\",\n",
    "    \"from langchain_chroma import Chroma\\n\",\n",
    "    \"import requests\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"from typing import List\\n\",\n",
    "    \"from dotenv import load_dotenv\\n\",\n",
    "    \"\\n\",\n",
    "    \"load_dotenv()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Custom Hugging Face Embeddings Class\\n\",\n",
    "    \"class HuggingFaceEmbeddings:\\n\",\n",
    "    \"    def __init__(self, api_token=None, model_name=\\\"sentence-transformers/all-MiniLM-L6-v2\\\"):\\n\",\n",
    "    \"        self.api_token = api_token or os.getenv(\\\"HUGGINGFACE_API_TOKEN\\\")\\n\",\n",
    "    \"        self.model_name = model_name\\n\",\n",
    "    \"        self.api_url = f\\\"https://api-inference.huggingface.co/pipeline/feature-extraction/{model_name}\\\"\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if not self.api_token:\\n\",\n",
    "    \"            print(\\\"Warning: No Hugging Face API token found. Please set HUGGINGFACE_API_TOKEN in your .env file\\\")\\n\",\n",
    "    \"            print(\\\"You can get a free token from: https://huggingface.co/settings/tokens\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def embed_documents(self, texts: List[str]) -> List[List[float]]:\\n\",\n",
    "    \"        \\\"\\\"\\\"Embed a list of documents using Hugging Face API\\\"\\\"\\\"\\n\",\n",
    "    \"        if not self.api_token:\\n\",\n",
    "    \"            raise ValueError(\\\"Hugging Face API token is required\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        headers = {\\\"Authorization\\\": f\\\"Bearer {self.api_token}\\\"}\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        embeddings = []\\n\",\n",
    "    \"        for text in texts:\\n\",\n",
    "    \"            try:\\n\",\n",
    "    \"                response = requests.post(\\n\",\n",
    "    \"                    self.api_url,\\n\",\n",
    "    \"                    headers=headers,\\n\",\n",
    "    \"                    json={\\\"inputs\\\": text, \\\"options\\\": {\\\"wait_for_model\\\": True}}\\n\",\n",
    "    \"                )\\n\",\n",
    "    \"                response.raise_for_status()\\n\",\n",
    "    \"                embedding = response.json()\\n\",\n",
    "    \"                # Convert to list of floats\\n\",\n",
    "    \"                if isinstance(embedding, list) and len(embedding) > 0:\\n\",\n",
    "    \"                    embeddings.append(embedding[0])\\n\",\n",
    "    \"                else:\\n\",\n",
    "    \"                    embeddings.append(embedding)\\n\",\n",
    "    \"            except Exception as e:\\n\",\n",
    "    \"                print(f\\\"Error embedding text: {e}\\\")\\n\",\n",
    "    \"                # Return zero vector as fallback\\n\",\n",
    "    \"                embeddings.append([0.0] * 384)  # Default size for all-MiniLM-L6-v2\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        return embeddings\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def embed_query(self, text: str) -> List[float]:\\n\",\n",
    "    \"        \\\"\\\"\\\"Embed a single query text\\\"\\\"\\\"\\n\",\n",
    "    \"        return self.embed_documents([text])[0]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Alternative: Local embeddings (completely free, no API needed)\\n\",\n",
    "    \"class LocalEmbeddings:\\n\",\n",
    "    \"    def __init__(self, model_name=\\\"all-MiniLM-L6-v2\\\"):\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            from sentence_transformers import SentenceTransformer\\n\",\n",
    "    \"            self.model = SentenceTransformer(model_name)\\n\",\n",
    "    \"            print(f\\\"Using local model: {model_name}\\\")\\n\",\n",
    "    \"        except ImportError:\\n\",\n",
    "    \"            print(\\\"sentence-transformers not installed. Run: pip install sentence-transformers\\\")\\n\",\n",
    "    \"            raise\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def embed_documents(self, texts: List[str]) -> List[List[float]]:\\n\",\n",
    "    \"        \\\"\\\"\\\"Embed documents using local model\\\"\\\"\\\"\\n\",\n",
    "    \"        return self.model.encode(texts).tolist()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def embed_query(self, text: str) -> List[float]:\\n\",\n",
    "    \"        \\\"\\\"\\\"Embed a single query text\\\"\\\"\\\"\\n\",\n",
    "    \"        return self.model.encode([text]).tolist()[0]\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"\\n\",\n",
    "    \"books = pd.read_csv('books_cleaned.csv')\\n\",\n",
    "    \"books.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Save book descriptions to text file\\n\",\n",
    "    \"books[\\\"tagged_description\\\"].to_csv(\\\"tagged_descriptions.txt\\\",\\n\",\n",
    "    \"                                     index=False,\\n\",\n",
    "    \"                                     header=False,\\n\",\n",
    "    \"                                   )\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load and split documents\\n\",\n",
    "    \"raw_documents = TextLoader(\\\"tagged_descriptions.txt\\\").load()\\n\",\n",
    "    \"\\n\",\n",
    "    \"text_splitter = CharacterTextSplitter(chunk_size=0, chunk_overlap=0, separator='\\\\n')\\n\",\n",
    "    \"documents = text_splitter.split_documents(raw_documents)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Created {len(documents)} document chunks\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Choose your embedding method:\\n\",\n",
    "    \"# Option 1: Hugging Face API (requires API token)\\n\",\n",
    "    \"# Option 2: Local embeddings (completely free, no API needed)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# For Hugging Face API (uncomment if you have API token):\\n\",\n",
    "    \"# embeddings = HuggingFaceEmbeddings()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# For local embeddings (recommended for free usage):\\n\",\n",
    "    \"embeddings = LocalEmbeddings()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Embeddings initialized successfully!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create vector database\\n\",\n",
    "    \"db_books = Chroma.from_documents(documents, embedding=embeddings)\\n\",\n",
    "    \"print(\\\"Vector database created successfully!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Test the search functionality\\n\",\n",
    "    \"query = \\\"sci-fi space adventure\\\"\\n\",\n",
    "    \"results = db_books.similarity_search(query, k=3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Search results for: '{query}'\\\")\\n\",\n",
    "    \"print(\\\"=\\\" * 50)\\n\",\n",
    "    \"for i, result in enumerate(results, 1):\\n\",\n",
    "    \"    print(f\\\"\\\\nResult {i}:\\\")\\n\",\n",
    "    \"    print(result.page_content[:200] + \\\"...\\\" if len(result.page_content) > 200 else result.page_content)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Function to get book recommendations\\n\",\n",
    "    \"def get_book_recommendations(query, k=5):\\n\",\n",
    "    \"    \\\"\\\"\\\"Get book recommendations based on a query\\\"\\\"\\\"\\n\",\n",
    "    \"    results = db_books.similarity_search(query, k=k)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    recommendations = []\\n\",\n",
    "    \"    for i, result in enumerate(results, 1):\\n\",\n",
    "    \"        # Extract book title from the description (assuming it's the first part)\\n\",\n",
    "    \"        content = result.page_content\\n\",\n",
    "    \"        title = content.split('\\\\n')[0] if '\\\\n' in content else content[:50]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        recommendations.append({\\n\",\n",
    "    \"            'rank': i,\\n\",\n",
    "    \"            'title': title,\\n\",\n",
    "    \"            'description': content[:200] + \\\"...\\\" if len(content) > 200 else content\\n\",\n",
    "    \"        })\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return recommendations\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Test with different queries\\n\",\n",
    "    \"test_queries = [\\n\",\n",
    "    \"    \\\"mystery detective crime\\\",\\n\",\n",
    "    \"    \\\"romance love story\\\",\\n\",\n",
    "    \"    \\\"fantasy magic dragons\\\",\\n\",\n",
    "    \"    \\\"historical fiction war\\\"\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"for query in test_queries:\\n\",\n",
    "    \"    print(f\\\"\\\\n\\\\nRecommendations for: '{query}'\\\")\\n\",\n",
    "    \"    print(\\\"=\\\" * 60)\\n\",\n",
    "    \"    recommendations = get_book_recommendations(query, k=3)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for rec in recommendations:\\n\",\n",
    "    \"        print(f\\\"\\\\n{rec['rank']}. {rec['title']}\\\")\\n\",\n",
    "    \"        print(f\\\"   {rec['description']}\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.5\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
